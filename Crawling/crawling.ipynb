{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_keys import SP_DC, SP_KEY, CLIENT_SECRET\n",
    "from syrics.api import Spotify\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotify_token as st\n",
    "\n",
    "data = st.start_session(SP_DC, SP_KEY)\n",
    "access_token = data[0]\n",
    "expiration_date = data[1]\n",
    "sp = Spotify(SP_DC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLyrics(lyrics):\n",
    "    if lyrics == None:\n",
    "        return None\n",
    "    lyrics = lyrics['lyrics']\n",
    "    lines = lyrics['lines']\n",
    "    to_return = []\n",
    "    for line in lines:\n",
    "        to_return.append(line['words'])\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchArtists(name, retry_count=8):\n",
    "    global data, access_token, expiration_date, sp\n",
    "    for i in range(retry_count):\n",
    "        try:\n",
    "            endpoint = \"https://api.spotify.com/v1/search\"\n",
    "            q = name\n",
    "            type = [\"artist\"]\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {access_token}\"\n",
    "            }\n",
    "            params = {\n",
    "                \"q\": q,\n",
    "                \"type\": type\n",
    "            }\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                spotify_href = response.json()['artists']['items'][0]['external_urls']['spotify']\n",
    "                id = spotify_href.split(\"/\")[-1]\n",
    "                return id\n",
    "            elif response.status_code == 401:\n",
    "                data = st.start_session(SP_DC, SP_KEY)\n",
    "                access_token = data[0]\n",
    "                expiration_date = data[1]\n",
    "                sp = Spotify(SP_DC)\n",
    "                continue  # Retry the request with the new access token\n",
    "            elif response.status_code == 403:\n",
    "                break  # Break out of the loop and return None\n",
    "            elif response.status_code == 429 or response.status_code == 503:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "            else:\n",
    "                raise Exception(response.status_code, response.text)\n",
    "        except Exception as e:\n",
    "            if i == retry_count - 1:\n",
    "                raise e\n",
    "            else:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArtistsAlbums(id, limit=50, retry_count=8):\n",
    "    global data, access_token, expiration_date, sp\n",
    "    for i in range(retry_count):\n",
    "        try:\n",
    "            endpoint = f\"https://api.spotify.com/v1/artists/{id}/albums\"\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {access_token}\"\n",
    "            }\n",
    "            market = \"US\"\n",
    "            limit = limit\n",
    "            params = {\n",
    "                \"market\": market,\n",
    "                \"limit\": limit\n",
    "            }\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                albums = response.json()['items']\n",
    "                to_return = []\n",
    "                for album in albums:\n",
    "                    return_album = {\n",
    "                        \"name\": album['name'],\n",
    "                        \"id\": album['id'],\n",
    "                        \"release_date\": album['release_date'],\n",
    "                        \"album_type\": album['album_type']\n",
    "                    }\n",
    "                    to_return.append(return_album)\n",
    "                return to_return\n",
    "            elif response.status_code == 401:\n",
    "                data = st.start_session(SP_DC, SP_KEY)\n",
    "                access_token = data[0]\n",
    "                expiration_date = data[1]\n",
    "                sp = Spotify(SP_DC)\n",
    "                continue  # Retry the request with the new access token\n",
    "            elif response.status_code == 403:\n",
    "                break  # Break out of the loop and return an empty list\n",
    "            elif response.status_code == 429 or response.status_code == 503:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "            else:\n",
    "                raise Exception(\"Error getting albums\")\n",
    "        except Exception as e:\n",
    "            if i == retry_count - 1:\n",
    "                raise e\n",
    "            else:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAlbumTracks(album_id, retry_count=8):\n",
    "    global data, access_token, expiration_date, sp\n",
    "    for i in range(retry_count):\n",
    "        try:\n",
    "            endpoint = f\"https://api.spotify.com/v1/albums/{album_id}/tracks\"\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {access_token}\"\n",
    "            }\n",
    "            limit = 50\n",
    "            params = {\n",
    "                \"limit\": limit\n",
    "            }\n",
    "            response = requests.get(endpoint, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                tracks = response.json()['items']\n",
    "                to_return = []\n",
    "                for track in tracks:\n",
    "                    return_track = {\n",
    "                        \"name\": track['name'],\n",
    "                        \"id\": track['id'],\n",
    "                        \"duration_ms\": track['duration_ms']\n",
    "                    }\n",
    "                    to_return.append(return_track)\n",
    "                return to_return\n",
    "            elif response.status_code == 401:\n",
    "                data = st.start_session(SP_DC, SP_KEY)\n",
    "                access_token = data[0]\n",
    "                expiration_date = data[1]\n",
    "                sp = Spotify(SP_DC)\n",
    "                continue  # Retry the request with the new access token\n",
    "            elif response.status_code == 403:\n",
    "                break  # Break out of the loop and return an empty list\n",
    "            elif response.status_code == 429 or response.status_code == 503:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "            else:\n",
    "                raise Exception(\"Error getting tracks\")\n",
    "        except Exception as e:\n",
    "            if i == retry_count - 1:\n",
    "                raise e\n",
    "            else:\n",
    "                time.sleep(20)  # Wait for a few seconds before retrying\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLyrics(name, limit = 50):\n",
    "    artist_id = searchArtists(name)\n",
    "    albums = getArtistsAlbums(artist_id, limit)\n",
    "    to_return = []\n",
    "    for album in albums:\n",
    "        album_name = album['name']\n",
    "        album_id = album['id']\n",
    "        try:\n",
    "            album_tracks = getAlbumTracks(album_id)\n",
    "            for track in album_tracks:\n",
    "                track_id = track['id']\n",
    "                if track_id == None:\n",
    "                    lyrics = []\n",
    "                else:\n",
    "                    lyrics = cleanLyrics(sp.get_lyrics(track_id))\n",
    "                    to_return.append({\n",
    "                        \"artist\": name,\n",
    "                        \"album\": album_name,\n",
    "                        \"track\": track['name'],\n",
    "                        \"track_id\": track_id,\n",
    "                        \"lyrics\": lyrics,\n",
    "                        \"duration_ms\": track['duration_ms']\n",
    "                    })\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_artists = [\"Taylor Swift\", \"CoCoMelon\", \"Keshi\", \"Conan Gray\", \"Slayer\", \"Black Sabbath\", \"Khalid\", \"Lana Del Ray\", \"IU\", \"YOASOBI\", \"LilyPichu\", \"League of Legends\"]\n",
    "top_x_artists = [\n",
    "    \"The Weeknd\", \"Taylor Swift\", \"Rihanna\", \"Ariana Grande\", \"Drake\",\n",
    "    \"Kanye West\", \"Justin Bieber\", \"Dua Lipa\", \"Coldplay\", \"Bruno Mars\",\n",
    "    \"Beyonc√©\", \"SZA\", \"David Guetta\", \"Ed Sheeran\", \"Eminem\", \"Bad Bunny\",\n",
    "    \"Miley Cyrus\", \"Marshmello\", \"Travis Scott\", \"Calvin Harris\", \"Billie Eilish\",\n",
    "    \"Doja Cat\", \"21 Savage\", \"Maroon 5\", \"Shakira\", \"Imagine Dragons\",\n",
    "    \"Tate McRae\", \"Post Malone\", \"Lady Gaga\", \"Katy Perry\", \"Olivia Rodrigo\",\n",
    "    \"Lana Del Rey\", \"Harry Styles\", \"Adele\", \"Peso Pluma\", \"Playboi Carti\",\n",
    "    \"KAROL G\", \"Nicki Minaj\", \"Sia\", \"Ti√´sto\", \"Benson Boone\", \"J Balvin\",\n",
    "    \"Kendrick Lamar\", \"Ty Dolla $ign\", \"Queen\", \"Arctic Monkeys\", \"Future\",\n",
    "    \"Metro Boomin\", \"Elton John\", \"Khalid\", \"Sam Smith\", \"Daddy Yankee\",\n",
    "    \"Selena Gomez\", \"Chris Brown\", \"Jack Harlow\", \"OneRepublic\", \"USHER\",\n",
    "    \"Justin Timberlake\", \"Pitbull\", \"Feid\", \"Shawn Mendes\", \"Madonna\",\n",
    "    \"Myke Towers\", \"One Direction\", \"Halsey\", \"Kali Uchis\", \"Linkin Park\",\n",
    "    \"J. Cole\", \"Maluma\", \"Rauw Alejandro\", \"Black Eyed Peas\", \"The Chainsmokers\",\n",
    "    \"Ozuna\", \"Bebe Rexha\", \"Michael Jackson\", \"Camila Cabello\", \"Bizarrap\",\n",
    "    \"James Arthur\", \"Teddy Swims\", \"Swae Lee\", \"Avicii\", \"Lil Wayne\",\n",
    "    \"Ellie Goulding\", \"Jason Derulo\", \"Arijit Singh\", \"JAY-Z\", \"Mitski\",\n",
    "    \"XXXTENTACION\", \"Britney Spears\", \"P!nk\", \"Charlie Puth\", \"Manuel Turizo\",\n",
    "    \"Noah Kahan\", \"The Neighbourhood\", \"Pharrell Williams\", \"Lewis Capaldi\",\n",
    "    \"Ava Max\", \"50 Cent\", \"Pritam\", \"CoCoMelon\", \"Keshi\", \"Conan Gray\", \"Slayer\",\n",
    "    \"Black Sabbath\", \"LilyPichu\", \"League of Legends\", \"Billy Joel\", \"AC/DC\", \"Demi Lovato\",\n",
    "    \"Twenty One Pilots\", \"Panic! At The Disco\", \"5 Seconds of Summer\", \"Fall Out Boy\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_x = []\n",
    "for artists in top_x_artists:\n",
    "    # generate lyrics also runs through all the other functions, so almost every song by the artist is added to the list\n",
    "    top_x += generateLyrics(artists)\n",
    "\n",
    "df = pd.DataFrame(top_x)\n",
    "df.to_csv(\"top_x.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint because crawling takes days\n",
    "df = pd.read_csv(\"top_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-running to catch missing lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show just the rows where lyrics are None or NaN\n",
    "lyricalest_df = df[df['lyrics'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows where \"Soundtrack\" is in the album name\n",
    "# soundtracks probably won't have lyrics\n",
    "lyricalest_df = lyricalest_df[lyricalest_df['album'].apply(lambda x: \"Soundtrack\" not in x)]\n",
    "lyricalest_df.reset_index(drop=True, inplace=True)\n",
    "lyricalest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through lyrical_df and get the lyrics for each track\n",
    "data = st.start_session(SP_DC, SP_KEY)\n",
    "access_token = data[0]\n",
    "expiration_date = data[1]\n",
    "sp = Spotify(SP_DC)\n",
    "\n",
    "new = []\n",
    "\n",
    "for i, row in lyricalest_df.iterrows():\n",
    "    # prevent the access token from expiring\n",
    "    if i % 1000 == 0:\n",
    "        data = st.start_session(SP_DC, SP_KEY)\n",
    "        access_token = data[0]\n",
    "        expiration_date = data[1]\n",
    "        sp = Spotify(SP_DC)\n",
    "    \n",
    "    # to check progress\n",
    "    if i % 100 == 0 and i != 0:\n",
    "        print(new[i-1])\n",
    "        print(i)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    artist = row['artist']\n",
    "    album = row['album']\n",
    "    track = row['track']\n",
    "    track_id = row['track_id']\n",
    "    lyrics = cleanLyrics(sp.get_lyrics(track_id))\n",
    "    new.append({\n",
    "        \"artist\": artist,\n",
    "        \"album\": album,\n",
    "        \"track\": track,\n",
    "        \"track_id\": track_id,\n",
    "        \"lyrics\": lyrics\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging with first pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricalest_df = pd.DataFrame(new)\n",
    "lyricalest_df.to_csv(\"top_x_additional.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint two\n",
    "lyricalest_df = pd.read_csv(\"top_x_additional.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and NaNs\n",
    "df = df.drop_duplicates(subset=['lyrics'])\n",
    "df = df.dropna(subset=['lyrics'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.concat([df, lyricalest_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(columns=['Unnamed: 0'])\n",
    "clean_df = clean_df.drop_duplicates(subset=['lyrics'])\n",
    "clean_df = clean_df.dropna(subset=['lyrics'])\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "\n",
    "clean_df.to_csv(\"top_x_cleaned.csv\", index=True)\n",
    "\n",
    "# flatten lyrics\n",
    "# lyrics were initially stored as strings, so we need to convert them back to lists\n",
    "import ast\n",
    "\n",
    "clean_df['lyrics'] = clean_df['lyrics'].apply(lambda x: \" \".join(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 3\n",
    "clean_df = pd.read_csv(\"top_x_cleaned.csv\")\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling and adding genre information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique artists\n",
    "unique_artists = clean_df['artist'].unique()\n",
    "artist_genre = {}\n",
    "for artist in unique_artists:\n",
    "    id = searchArtists(artist)\n",
    "    endpoint = f\"https://api.spotify.com/v1/artists/{id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        genres = response.json()['genres']\n",
    "    else:\n",
    "        genres = None\n",
    "\n",
    "    artist_genre[artist] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['genre'] = clean_df['artist'].apply(lambda x: artist_genre[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"finalfinalfinalfinalfinal.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 4\n",
    "df = pd.read_csv(\"finalfinalfinalfinalfinal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Non English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['lyrics'].str.contains(r'^[a-zA-Z0-9 !@#$%^&*()_+-=,‚ô´‚ô™\\'\\\"?‚Äî{}‚Äì\\[\\]„Ö§]*$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def getArtistFromTrackId(id):\n",
    "    endpoint = f\"https://api.spotify.com/v1/tracks/{id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}\")\n",
    "    \n",
    "    track_info = response.json()\n",
    "    artist_names = []\n",
    "    for name in track_info['artists']:\n",
    "        artist_names.append(name['name'])\n",
    "    \n",
    "    return artist_names\n",
    "\n",
    "def getReleaseDateFromId(id):\n",
    "    endpoint = f\"https://api.spotify.com/v1/tracks/{id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}\")\n",
    "    \n",
    "    track_info = response.json()\n",
    "    release_date = track_info['album']['release_date']\n",
    "\n",
    "    return release_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowing songs to have multiple artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artists'] = None\n",
    "for i, row in df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            artists = getArtistFromTrackId(row['track_id'])\n",
    "            df.at[i, 'artists'] = artists\n",
    "            success = True\n",
    "        except:\n",
    "            data = st.start_session(SP_DC, SP_KEY)\n",
    "            access_token = data[0]\n",
    "            expiration_date = data[1]\n",
    "            sp = Spotify(SP_DC)\n",
    "            time.sleep(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['artist'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 5\n",
    "df.to_csv(\"multiartists.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional information for Frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "URL is to allow users to get to the song on Spotify.\n",
    "Image is to allow users to see the album art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"multiartists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMisc(id):\n",
    "    endpoint = f\"https://api.spotify.com/v1/tracks/{id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    data = response.json()\n",
    "    url = data[\"external_urls\"][\"spotify\"]\n",
    "    name = data[\"name\"]\n",
    "    preview_url = data[\"preview_url\"]\n",
    "    image = data[\"album\"][\"images\"][0][\"url\"]\n",
    "    return url, name, preview_url, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n"
     ]
    }
   ],
   "source": [
    "df['url'] = None\n",
    "df['name'] = None\n",
    "df['preview_url'] = None\n",
    "df['image'] = None\n",
    "for i, row in df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            url, name, preview, image = getMisc(row['track_id'])\n",
    "            df.at[i, \"url\"] = url\n",
    "            df.at[i, \"name\"] = name\n",
    "            df.at[i, \"preview_url\"] = preview\n",
    "            df.at[i, \"image\"] = image\n",
    "            success = True\n",
    "        except:\n",
    "            data = st.start_session(SP_DC, SP_KEY)\n",
    "            access_token = data[0]\n",
    "            expiration_date = data[1]\n",
    "            sp = Spotify(SP_DC)\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"additional_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding release date information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'] = None\n",
    "for i, row in df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            release_date = getReleaseDateFromId(row['track_id'])\n",
    "            df.at[i, 'release_date'] = release_date\n",
    "            success = True\n",
    "        except:\n",
    "            data = st.start_session(SP_DC, SP_KEY)\n",
    "            access_token = data[0]\n",
    "            expiration_date = data[1]\n",
    "            sp = Spotify(SP_DC)\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding explicit flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExplicit(id):\n",
    "    endpoint = f\"https://api.spotify.com/v1/tracks/{id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Request failed with status {response.status_code}\")\n",
    "    \n",
    "    track_info = response.json()\n",
    "    explicit = track_info['explicit']\n",
    "\n",
    "    return explicit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"explicit\"] = None\n",
    "for i, row in df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            explicit = isExplicit(row['track_id'])\n",
    "            df.at[i, 'explicit'] = explicit\n",
    "            success = True\n",
    "        except:\n",
    "            data = st.start_session(SP_DC, SP_KEY)\n",
    "            access_token = data[0]\n",
    "            expiration_date = data[1]\n",
    "            sp = Spotify(SP_DC)\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing remixes and re-releases\n",
    "---\n",
    "Example, Taylor Swift's original songs, vs Taylor's Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove songs where \"remix\" is in track\n",
    "df = df[~df['track'].apply(lambda x: \"Remix\" in x)]\n",
    "\n",
    "# create new column called normalized_lyrics\n",
    "# this column will contain the lyrics with all non-alphanumeric characters removed\n",
    "import re\n",
    "\n",
    "df['normalized_lyrics'] = df['lyrics'].apply(lambda x: re.sub(r'[^a-zA-Z0-9 ]', '', x))\n",
    "df['normalized_lyrics'] = df['normalized_lyrics'].apply(lambda x: x.lower())\n",
    "# remove all spaces\n",
    "df['normalized_lyrics'] = df['normalized_lyrics'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "\n",
    "# # remove songs where normalized_lyrics is duped\n",
    "df = df.drop_duplicates(subset=['normalized_lyrics'])\n",
    "\n",
    "# # remove normalized_lyrics column\n",
    "df.drop(columns=['normalized_lyrics'], inplace=True)\n",
    "\n",
    "df.to_csv(\"final_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>track_id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Highlights (Deluxe)</td>\n",
       "      <td>Die For You</td>\n",
       "      <td>2vz6HIZBaQOnWCH7kKhKQH</td>\n",
       "      <td>I'm findin' ways to articulate The feeling I'm...</td>\n",
       "      <td>4 minutes 20 seconds</td>\n",
       "      <td>['canadian contemporary r&amp;b', 'canadian pop', ...</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>False</td>\n",
       "      <td>['The Weeknd']</td>\n",
       "      <td>https://open.spotify.com/track/2vz6HIZBaQOnWCH...</td>\n",
       "      <td>Die For You</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/e16852119b0d41ef...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c87bfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Highlights (Deluxe)</td>\n",
       "      <td>Starboy (feat. Daft Punk)</td>\n",
       "      <td>218WdV0d4ijtTtPTKGuf1E</td>\n",
       "      <td>I'm tryna put you in the worst mood, ah P1 cle...</td>\n",
       "      <td>3 minutes 50 seconds</td>\n",
       "      <td>['canadian contemporary r&amp;b', 'canadian pop', ...</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>True</td>\n",
       "      <td>['The Weeknd', 'Daft Punk']</td>\n",
       "      <td>https://open.spotify.com/track/218WdV0d4ijtTtP...</td>\n",
       "      <td>Starboy (feat. Daft Punk)</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/508e00c3470094fe...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c87bfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Highlights (Deluxe)</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>6YckHetPOkzxtXXaYx0Gt1</td>\n",
       "      <td>Ooh Na-na, yeah I saw you dancing in a crowded...</td>\n",
       "      <td>3 minutes 35 seconds</td>\n",
       "      <td>['canadian contemporary r&amp;b', 'canadian pop', ...</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>True</td>\n",
       "      <td>['The Weeknd']</td>\n",
       "      <td>https://open.spotify.com/track/6YckHetPOkzxtXX...</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/59b0119674967b35...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c87bfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Highlights (Deluxe)</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>04948IGlqY1vSh7AHbueiQ</td>\n",
       "      <td>Yeah ‚ô™ I've been tryna call I've been on my ow...</td>\n",
       "      <td>3 minutes 20 seconds</td>\n",
       "      <td>['canadian contemporary r&amp;b', 'canadian pop', ...</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>False</td>\n",
       "      <td>['The Weeknd']</td>\n",
       "      <td>https://open.spotify.com/track/04948IGlqY1vSh7...</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/deb0fb99d88264e4...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c87bfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Highlights (Deluxe)</td>\n",
       "      <td>In Your Eyes</td>\n",
       "      <td>4SD0V2HMxkBupk6ml9alm4</td>\n",
       "      <td>Oh, yeah I just pretend, uh That I'm in the da...</td>\n",
       "      <td>3 minutes 57 seconds</td>\n",
       "      <td>['canadian contemporary r&amp;b', 'canadian pop', ...</td>\n",
       "      <td>2024-02-09</td>\n",
       "      <td>True</td>\n",
       "      <td>['The Weeknd']</td>\n",
       "      <td>https://open.spotify.com/track/4SD0V2HMxkBupk6...</td>\n",
       "      <td>In Your Eyes</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/88e6d52b150be7e4...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273c87bfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20792</th>\n",
       "      <td>America's Suitehearts</td>\n",
       "      <td>America's Suitehearts - Acoustic</td>\n",
       "      <td>0zRX1ItX2sh7PJtKuvOuO5</td>\n",
       "      <td>You could have knocked me out with a feather I...</td>\n",
       "      <td>3 minutes 40 seconds</td>\n",
       "      <td>['emo', 'modern rock', 'pop', 'rock']</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>['Fall Out Boy']</td>\n",
       "      <td>https://open.spotify.com/track/0zRX1ItX2sh7PJt...</td>\n",
       "      <td>America's Suitehearts - Acoustic</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/0f7b111fe42cea99...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b2738d11ff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20794</th>\n",
       "      <td>So Sick</td>\n",
       "      <td>So Sick - (BBC Radio 1 - Live Lounge)</td>\n",
       "      <td>0Csc6pK1zv3k071tSWqJ5D</td>\n",
       "      <td>Gotta change my answering machine Now that I'm...</td>\n",
       "      <td>2 minutes 54 seconds</td>\n",
       "      <td>['emo', 'modern rock', 'pop', 'rock']</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>['Fall Out Boy']</td>\n",
       "      <td>https://open.spotify.com/track/0Csc6pK1zv3k071...</td>\n",
       "      <td>So Sick - (BBC Radio 1 - Live Lounge)</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8c08158f0d9b5946...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273bbb2c5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>I'm Like A Lawyer With The Way I'm Always Tryi...</td>\n",
       "      <td>I'm Like A Lawyer With The Way I'm Always Tryi...</td>\n",
       "      <td>7eOlcfmf0J6rvWQrBVhorO</td>\n",
       "      <td>Last year's wishes are this year's apologies E...</td>\n",
       "      <td>3 minutes 36 seconds</td>\n",
       "      <td>['emo', 'modern rock', 'pop', 'rock']</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>['Fall Out Boy']</td>\n",
       "      <td>https://open.spotify.com/track/7eOlcfmf0J6rvWQ...</td>\n",
       "      <td>I'm Like A Lawyer With The Way I'm Always Tryi...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/3e26c8d0d3e82e13...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b2737eb920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>I'm Like A Lawyer With The Way I'm Always Tryi...</td>\n",
       "      <td>Golden - Live From Hammersmith Palais</td>\n",
       "      <td>2nzAvHE8a63oX0PQTMq2UZ</td>\n",
       "      <td>How cruel is the golden rule? When the lives w...</td>\n",
       "      <td>2 minutes 35 seconds</td>\n",
       "      <td>['emo', 'modern rock', 'pop', 'rock']</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>['Fall Out Boy']</td>\n",
       "      <td>https://open.spotify.com/track/2nzAvHE8a63oX0P...</td>\n",
       "      <td>Golden - Live From Hammersmith Palais</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c1c2a7daaa3b4558...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b2737eb920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>\"The Take Over, The Breaks Over\"</td>\n",
       "      <td>Thriller - 2006/AOL Music Sessions</td>\n",
       "      <td>3Eljf6kcc09IJPjTvUH2nA</td>\n",
       "      <td>Yeah, what you critics said would never happen...</td>\n",
       "      <td>3 minutes 23 seconds</td>\n",
       "      <td>['emo', 'modern rock', 'pop', 'rock']</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>['Fall Out Boy']</td>\n",
       "      <td>https://open.spotify.com/track/3Eljf6kcc09IJPj...</td>\n",
       "      <td>Thriller - 2006/AOL Music Sessions</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c1b5585480c41c6d...</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d0000b273d4fcf9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18516 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   album  \\\n",
       "0                                The Highlights (Deluxe)   \n",
       "1                                The Highlights (Deluxe)   \n",
       "2                                The Highlights (Deluxe)   \n",
       "3                                The Highlights (Deluxe)   \n",
       "4                                The Highlights (Deluxe)   \n",
       "...                                                  ...   \n",
       "20792                              America's Suitehearts   \n",
       "20794                                            So Sick   \n",
       "20795  I'm Like A Lawyer With The Way I'm Always Tryi...   \n",
       "20796  I'm Like A Lawyer With The Way I'm Always Tryi...   \n",
       "20797                   \"The Take Over, The Breaks Over\"   \n",
       "\n",
       "                                                   track  \\\n",
       "0                                            Die For You   \n",
       "1                              Starboy (feat. Daft Punk)   \n",
       "2                                        Save Your Tears   \n",
       "3                                        Blinding Lights   \n",
       "4                                           In Your Eyes   \n",
       "...                                                  ...   \n",
       "20792                   America's Suitehearts - Acoustic   \n",
       "20794              So Sick - (BBC Radio 1 - Live Lounge)   \n",
       "20795  I'm Like A Lawyer With The Way I'm Always Tryi...   \n",
       "20796              Golden - Live From Hammersmith Palais   \n",
       "20797                 Thriller - 2006/AOL Music Sessions   \n",
       "\n",
       "                     track_id  \\\n",
       "0      2vz6HIZBaQOnWCH7kKhKQH   \n",
       "1      218WdV0d4ijtTtPTKGuf1E   \n",
       "2      6YckHetPOkzxtXXaYx0Gt1   \n",
       "3      04948IGlqY1vSh7AHbueiQ   \n",
       "4      4SD0V2HMxkBupk6ml9alm4   \n",
       "...                       ...   \n",
       "20792  0zRX1ItX2sh7PJtKuvOuO5   \n",
       "20794  0Csc6pK1zv3k071tSWqJ5D   \n",
       "20795  7eOlcfmf0J6rvWQrBVhorO   \n",
       "20796  2nzAvHE8a63oX0PQTMq2UZ   \n",
       "20797  3Eljf6kcc09IJPjTvUH2nA   \n",
       "\n",
       "                                                  lyrics  \\\n",
       "0      I'm findin' ways to articulate The feeling I'm...   \n",
       "1      I'm tryna put you in the worst mood, ah P1 cle...   \n",
       "2      Ooh Na-na, yeah I saw you dancing in a crowded...   \n",
       "3      Yeah ‚ô™ I've been tryna call I've been on my ow...   \n",
       "4      Oh, yeah I just pretend, uh That I'm in the da...   \n",
       "...                                                  ...   \n",
       "20792  You could have knocked me out with a feather I...   \n",
       "20794  Gotta change my answering machine Now that I'm...   \n",
       "20795  Last year's wishes are this year's apologies E...   \n",
       "20796  How cruel is the golden rule? When the lives w...   \n",
       "20797  Yeah, what you critics said would never happen...   \n",
       "\n",
       "                   duration  \\\n",
       "0      4 minutes 20 seconds   \n",
       "1      3 minutes 50 seconds   \n",
       "2      3 minutes 35 seconds   \n",
       "3      3 minutes 20 seconds   \n",
       "4      3 minutes 57 seconds   \n",
       "...                     ...   \n",
       "20792  3 minutes 40 seconds   \n",
       "20794  2 minutes 54 seconds   \n",
       "20795  3 minutes 36 seconds   \n",
       "20796  2 minutes 35 seconds   \n",
       "20797  3 minutes 23 seconds   \n",
       "\n",
       "                                                   genre release_date  \\\n",
       "0      ['canadian contemporary r&b', 'canadian pop', ...   2024-02-09   \n",
       "1      ['canadian contemporary r&b', 'canadian pop', ...   2024-02-09   \n",
       "2      ['canadian contemporary r&b', 'canadian pop', ...   2024-02-09   \n",
       "3      ['canadian contemporary r&b', 'canadian pop', ...   2024-02-09   \n",
       "4      ['canadian contemporary r&b', 'canadian pop', ...   2024-02-09   \n",
       "...                                                  ...          ...   \n",
       "20792              ['emo', 'modern rock', 'pop', 'rock']   2008-01-01   \n",
       "20794              ['emo', 'modern rock', 'pop', 'rock']   2007-01-01   \n",
       "20795              ['emo', 'modern rock', 'pop', 'rock']   2007-01-01   \n",
       "20796              ['emo', 'modern rock', 'pop', 'rock']   2007-01-01   \n",
       "20797              ['emo', 'modern rock', 'pop', 'rock']   2007-01-01   \n",
       "\n",
       "       explicit                      artists  \\\n",
       "0         False               ['The Weeknd']   \n",
       "1          True  ['The Weeknd', 'Daft Punk']   \n",
       "2          True               ['The Weeknd']   \n",
       "3         False               ['The Weeknd']   \n",
       "4          True               ['The Weeknd']   \n",
       "...         ...                          ...   \n",
       "20792     False             ['Fall Out Boy']   \n",
       "20794     False             ['Fall Out Boy']   \n",
       "20795     False             ['Fall Out Boy']   \n",
       "20796     False             ['Fall Out Boy']   \n",
       "20797     False             ['Fall Out Boy']   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://open.spotify.com/track/2vz6HIZBaQOnWCH...   \n",
       "1      https://open.spotify.com/track/218WdV0d4ijtTtP...   \n",
       "2      https://open.spotify.com/track/6YckHetPOkzxtXX...   \n",
       "3      https://open.spotify.com/track/04948IGlqY1vSh7...   \n",
       "4      https://open.spotify.com/track/4SD0V2HMxkBupk6...   \n",
       "...                                                  ...   \n",
       "20792  https://open.spotify.com/track/0zRX1ItX2sh7PJt...   \n",
       "20794  https://open.spotify.com/track/0Csc6pK1zv3k071...   \n",
       "20795  https://open.spotify.com/track/7eOlcfmf0J6rvWQ...   \n",
       "20796  https://open.spotify.com/track/2nzAvHE8a63oX0P...   \n",
       "20797  https://open.spotify.com/track/3Eljf6kcc09IJPj...   \n",
       "\n",
       "                                                    name  \\\n",
       "0                                            Die For You   \n",
       "1                              Starboy (feat. Daft Punk)   \n",
       "2                                        Save Your Tears   \n",
       "3                                        Blinding Lights   \n",
       "4                                           In Your Eyes   \n",
       "...                                                  ...   \n",
       "20792                   America's Suitehearts - Acoustic   \n",
       "20794              So Sick - (BBC Radio 1 - Live Lounge)   \n",
       "20795  I'm Like A Lawyer With The Way I'm Always Tryi...   \n",
       "20796              Golden - Live From Hammersmith Palais   \n",
       "20797                 Thriller - 2006/AOL Music Sessions   \n",
       "\n",
       "                                             preview_url  \\\n",
       "0      https://p.scdn.co/mp3-preview/e16852119b0d41ef...   \n",
       "1      https://p.scdn.co/mp3-preview/508e00c3470094fe...   \n",
       "2      https://p.scdn.co/mp3-preview/59b0119674967b35...   \n",
       "3      https://p.scdn.co/mp3-preview/deb0fb99d88264e4...   \n",
       "4      https://p.scdn.co/mp3-preview/88e6d52b150be7e4...   \n",
       "...                                                  ...   \n",
       "20792  https://p.scdn.co/mp3-preview/0f7b111fe42cea99...   \n",
       "20794  https://p.scdn.co/mp3-preview/8c08158f0d9b5946...   \n",
       "20795  https://p.scdn.co/mp3-preview/3e26c8d0d3e82e13...   \n",
       "20796  https://p.scdn.co/mp3-preview/c1c2a7daaa3b4558...   \n",
       "20797  https://p.scdn.co/mp3-preview/c1b5585480c41c6d...   \n",
       "\n",
       "                                                   image  \n",
       "0      https://i.scdn.co/image/ab67616d0000b273c87bfe...  \n",
       "1      https://i.scdn.co/image/ab67616d0000b273c87bfe...  \n",
       "2      https://i.scdn.co/image/ab67616d0000b273c87bfe...  \n",
       "3      https://i.scdn.co/image/ab67616d0000b273c87bfe...  \n",
       "4      https://i.scdn.co/image/ab67616d0000b273c87bfe...  \n",
       "...                                                  ...  \n",
       "20792  https://i.scdn.co/image/ab67616d0000b2738d11ff...  \n",
       "20794  https://i.scdn.co/image/ab67616d0000b273bbb2c5...  \n",
       "20795  https://i.scdn.co/image/ab67616d0000b2737eb920...  \n",
       "20796  https://i.scdn.co/image/ab67616d0000b2737eb920...  \n",
       "20797  https://i.scdn.co/image/ab67616d0000b273d4fcf9...  \n",
       "\n",
       "[18516 rows x 13 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(n^2) if I were to use difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_swift = df[df['artists'].str.contains(\"Taylor Swift\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_no_duplicates)):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# get the lyrics of the two songs\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     lyrics_i \u001b[38;5;241m=\u001b[39m df_no_duplicates\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_lyrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m     lyrics_j \u001b[38;5;241m=\u001b[39m \u001b[43mdf_no_duplicates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_lyrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# calculate the similarity ratio\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     similarity_ratio \u001b[38;5;241m=\u001b[39m difflib\u001b[38;5;241m.\u001b[39mSequenceMatcher(\u001b[38;5;28;01mNone\u001b[39;00m, lyrics_i, lyrics_j)\u001b[38;5;241m.\u001b[39mratio()\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1714\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# create a copy of the DataFrame to avoid modifying the original DataFrame\n",
    "df_no_duplicates = df.copy()\n",
    "\n",
    "# iterate over all pairs of songs\n",
    "for i in range(len(df_no_duplicates)):\n",
    "    for j in range(i + 1, len(df_no_duplicates)):\n",
    "        # get the lyrics of the two songs\n",
    "        lyrics_i = df_no_duplicates.iloc[i]['normalized_lyrics']\n",
    "        lyrics_j = df_no_duplicates.iloc[j]['normalized_lyrics']\n",
    "\n",
    "        # calculate the similarity ratio\n",
    "        similarity_ratio = difflib.SequenceMatcher(None, lyrics_i, lyrics_j).ratio()\n",
    "\n",
    "        # if the songs are more than 90% similar, consider them duplicates\n",
    "        if similarity_ratio > 0.9:\n",
    "            # drop the second song\n",
    "            df_no_duplicates = df_no_duplicates.drop(df_no_duplicates.index[j])\n",
    "\n",
    "# reset the index of the DataFrame\n",
    "df_no_duplicates = df_no_duplicates.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[63, 322, 321, 324, 74, 84, 92, 100, 106, 233, 331, 323, 328, 105, 322, 75, 305, 313, 78, 92, 91, 98, 232, 306, 303, 95, 97, 232, 306, 112, 271, 322, 305, 313, 321, 324, 302, 308, 309, 310, 329, 330, 306, 325, 327, 273, 277, 278, 279, 280, 281, 283, 284, 313, 324, 330] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         num_comparisons \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# drop the duplicates\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m taylor_swift_no_duplicates \u001b[38;5;241m=\u001b[39m \u001b[43mtaylor_swift_no_duplicates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# reset the index of the DataFrame\u001b[39;00m\n\u001b[0;32m     36\u001b[0m taylor_swift_no_duplicates \u001b[38;5;241m=\u001b[39m taylor_swift_no_duplicates\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kidriel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[63, 322, 321, 324, 74, 84, 92, 100, 106, 233, 331, 323, 328, 105, 322, 75, 305, 313, 78, 92, 91, 98, 232, 306, 303, 95, 97, 232, 306, 112, 271, 322, 305, 313, 321, 324, 302, 308, 309, 310, 329, 330, 306, 325, 327, 273, 277, 278, 279, 280, 281, 283, 284, 313, 324, 330] not found in axis'"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import time\n",
    "\n",
    "# create a copy of the DataFrame to avoid modifying the original DataFrame\n",
    "taylor_swift_no_duplicates = taylor_swift.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# number of comparisons\n",
    "num_comparisons = 0\n",
    "\n",
    "# list to hold the indices of the rows to be dropped\n",
    "drop_indices = []\n",
    "\n",
    "# iterate over all pairs of songs\n",
    "for i in range(len(taylor_swift_no_duplicates)):\n",
    "    for j in range(i + 1, len(taylor_swift_no_duplicates)):\n",
    "        # get the lyrics of the two songs\n",
    "        lyrics_i = taylor_swift_no_duplicates.iloc[i]['normalized_lyrics']\n",
    "        lyrics_j = taylor_swift_no_duplicates.iloc[j]['normalized_lyrics']\n",
    "\n",
    "        # calculate the similarity ratio\n",
    "        similarity_ratio = difflib.SequenceMatcher(None, lyrics_i, lyrics_j).ratio()\n",
    "\n",
    "        # if the songs are more than 90% similar, consider them duplicates\n",
    "        if similarity_ratio > 0.9:\n",
    "            # add the index of the second song to the list of indices to be dropped\n",
    "            drop_indices.append(j)\n",
    "\n",
    "        num_comparisons += 1\n",
    "\n",
    "# drop the duplicates\n",
    "taylor_swift_no_duplicates = taylor_swift_no_duplicates.drop(drop_indices)\n",
    "\n",
    "# reset the index of the DataFrame\n",
    "taylor_swift_no_duplicates = taylor_swift_no_duplicates.reset_index(drop=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "average_time = total_time / num_comparisons\n",
    "\n",
    "print(f\"Total time taken: {total_time} seconds\")\n",
    "print(f\"Average time per comparison: {average_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
